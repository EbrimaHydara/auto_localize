Please read this file content as a continuation from the AutoLoc_Code_4.txt file content.


19. web_app_jsx_file_localizer.py:
# web_app_jsx_file_localizer.py

import re
from localizers.web_localizers.web_app_file_localizer import WebAppFileLocalizer
from managers.error_manager import LocalizationRenderError, ResourceFileError, InvalidUserInputError

class WebAppJSXFileLocalizer(WebAppFileLocalizer):
    """
    The WebAppJSXFileLocalizer handles all JSX file-specific localization procedures.
    It inherits the WebAppFileLocalizer class and manages the localization process.
    """

    def __init__(self, source_code_id, files):
        super().__init__(source_code_id)
        self.files = files

        # Regular expression patterns for identifying translatable strings in JSX files
        self.translatable_patterns = [
            re.compile(r'(?<!{)(["\'])(?:(?=(\\?))\2.)*?\1'),  # Matches simple strings in double/single quotes not inside expressions
            re.compile(r'>{([^<>]*?)}<'),  # Matches strings between JSX tags (e.g., >Text<)
            re.compile(r'{`([^`]*?)`}')     # Matches template literals inside JSX
        ]

    def localize_files(self):
        """
        Localizes all the JSX files in self.files.
        """
        try:
            for jsx_file in self.files:
                self._process_jsx_file(jsx_file)
            print("Localization completed successfully.")
        except Exception as e:
            raise LocalizationRenderError(f"WebAppJSXFileLocalizer Error in localize_files: {str(e)}")

    def _process_jsx_file(self, jsx_file):
        """
        Processes an individual JSX file for localization.

        :param jsx_file: The path to the JSX file to process.
        """
        try:
            with open(jsx_file, 'r', encoding='utf-8') as file:
                content = file.read()

            self._mark_and_extract_strings(content, jsx_file)
        except Exception as e:
            raise LocalizationRenderError(f"WebAppJSXFileLocalizer Error in _process_jsx_file: {str(e)}")

    def _mark_and_extract_strings(self, content, jsx_file):
        """
        Marks and extracts all the translatable strings in the JSX file content and saves them to a JSON file.

        :param content: The content of the JSX file.
        :param jsx_file: The path to the JSX file being processed.
        """
        try:
            source_json = {}
            modified_content = content

            # Check if the namespace is enabled in app_settings
            use_namespace = self.app_settings['use_key_namespace']

            for pattern in self.translatable_patterns:
                matches = pattern.finditer(content)
                for match in matches:
                    original_string = match.group(0)
                    translatable_string = match.group(1).strip() if len(match.groups()) > 0 else match.group(0).strip()
                    if not translatable_string:
                        continue

                    # Generate a unique key for the translatable string
                    generated_key = self.generate_key(jsx_file)

                    # Determine the key without namespace for the JSON file
                    key_without_namespace = generated_key.split(':', 1)[-1] if use_namespace else generated_key

                    # Save the extracted string to the JSON file without the namespace prefix
                    source_json[key_without_namespace] = translatable_string

                    # Generate key with or without namespace for the replacement in modified content
                    key_for_replacement = generated_key if use_namespace else key_without_namespace

                    # Replace the string in the content with "{t('key_for_replacement')}"
                    replacement_string = f"{{{{t('{key_for_replacement}')}}}}"
                    modified_content = modified_content.replace(original_string, replacement_string)

            # Save the extracted strings to a JSON file
            if source_json:
                self.save_resource_files(source_json, jsx_file)

            # Save the modified JSX file
            self._save_jsx_file(modified_content, jsx_file)
        except Exception as e:
            raise ResourceFileError(f"WebAppJSXFileLocalizer Error in _mark_and_extract_strings: {str(e)}")

    def _save_jsx_file(self, content, jsx_file):
        """
        Saves the modified JSX file to replace the original.

        :param content: The modified content of the JSX file.
        :param jsx_file: The path to the JSX file being saved.
        """
        try:
            with open(jsx_file, 'w', encoding='utf-8') as file:
                file.write(content)
        except Exception as e:
            raise ResourceFileError(f"WebAppJSXFileLocalizer Error in _save_jsx_file: {str(e)}")






20. web_app_ts_file_localizer.py:
import re
from localizers.web_localizers.web_app_file_localizer import WebAppFileLocalizer
from managers.error_manager import LocalizationRenderError, ResourceFileError, InvalidUserInputError

class WebAppTSFileLocalizer(WebAppFileLocalizer):
    """
    The WebAppTSFileLocalizer handles all TS file-specific localization procedures.
    It inherits the WebAppFileLocalizer class and manages the localization process.
    """

    def __init__(self, source_code_id, files):
        super().__init__(source_code_id)
        self.files = files

        # Regular expression patterns for identifying Japanese strings while avoiding comments and concatenations
        self.comment_pattern = re.compile(r'//.*?$|/\*.*?\*/', re.DOTALL | re.MULTILINE)

        # Updated pattern to include backtick strings, while excluding concatenated strings and specific cases
        self.japanese_text_pattern = re.compile(r"""
            (?<![\+\w])\s*            # Negative lookbehind to ignore concatenations and object keys
            (["'`])                   # Match opening quote (single, double, or backtick) (capture group 1)
            (                         # Start group for the content to be matched
            (?:[^"'\n]*?)             # Lazily match any characters that are not newlines or quotes
            [\u3000-\u30FF\u4E00-\u9FFF]  # Match Japanese characters
            [^"'\n]*?                 # Lazily match any characters that are not newlines or quotes
            )                         # End group for the content to be matched
            \1                        # Match closing quote (same as opening)
            (?!\s*[\+\w])             # Negative lookahead to ignore concatenations and function calls
            |
            ^\s*(["'`])               # Match isolated opening quote at the beginning (capture group 2)
            (                         # Start group for isolated content to be matched
            (?:[^"'\n]*?)             # Lazily match any characters that are not newlines or quotes
            [\u3000-\u30FF\u4E00-\u9FFF]  # Match Japanese characters
            [^"'\n]*?                 # Lazily match any characters that are not newlines or quotes
            )                         # End group for isolated content to be matched
            \2                        # Match isolated closing quote (same as opening)
            (?![\w\+\)])              # Negative lookahead to avoid concatenations, function calls, or variable names
        """, re.VERBOSE)

        # Pattern to match specific cases like '福岡県' or prompts with Japanese characters
        self.specific_japanese_string_pattern = re.compile(r"""
            (["'`])                    # Match opening quote (capture group 1)
            ([\u3000-\u30FF\u4E00-\u9FFF]+)  # Match only Japanese characters
            \1                        # Match closing quote (same as opening)
        """, re.VERBOSE)

    def localize_files(self):
        """
        Localizes all the TS files in self.files.
        """
        try:
            for ts_file in self.files:
                self._process_ts_file(ts_file)
            print("Localization completed successfully.")
        except Exception as e:
            raise LocalizationRenderError(f"WebAppTSFileLocalizer Error in localize_files: {str(e)}")

    def _process_ts_file(self, ts_file):
        """
        Processes an individual TS file for localization.

        :param ts_file: The path to the TS file to process.
        """
        try:
            with open(ts_file, 'r', encoding='utf-8') as file:
                content = file.read()

            modified_content, source_json = self._mark_and_extract_japanese_strings(content, ts_file)

            # Save the extracted strings to a JSON file
            if source_json:
                self.save_resource_files(source_json, ts_file)

            # Save the modified TS file using the existing method
            self._save_ts_file(modified_content, ts_file)
        except Exception as e:
            raise LocalizationRenderError(f"WebAppTSFileLocalizer Error in _process_ts_file: {str(e)}")

    def _mark_and_extract_japanese_strings(self, content, ts_file):
        """
        Marks and extracts all the Japanese strings in the TS file content while preserving comments
        and avoiding concatenated strings.

        :param content: The content of the TS file.
        :param ts_file: The path to the TS file being processed.
        :return: Modified content with placeholders for Japanese texts, and source_json for extracted strings.
        """
        try:
            source_json = {}
            modified_content_segments = []

            # Check if the namespace is enabled in app_settings
            use_namespace = self.app_settings['use_key_namespace']

            # Function to replace Japanese strings in code segments
            def replace_in_code_segment(segment):
                def replace_function(match):
                    # Match group 1 or 2 for quote type, and group 2 or 3 for the text to be replaced
                    quote_type = match.group(1) or match.group(2)
                    original_text = match.group(2) if match.group(1) else match.group(3)

                    # Generate a unique key for the translatable string
                    generated_key = self.generate_key(ts_file)

                    # Determine the key without namespace for the JSON file
                    key_without_namespace = generated_key.split(':', 1)[-1] if use_namespace else generated_key

                    # Save the extracted string to the JSON file
                    source_json[key_without_namespace] = original_text

                    # Determine the correct replacement string based on quote type
                    if quote_type == "'":
                        # If the original string was in single quotes, use t("{generated_key}") in the replacement
                        replacement_string = f't("{generated_key}")'
                    elif quote_type == '"':
                        # If the original string was in double quotes, use t('{generated_key}') in the replacement
                        replacement_string = f"t('{generated_key}')"
                    elif quote_type == "`":
                        # If the original string was in backtick quotes, use t("{generated_key}") in the replacement
                        replacement_string = f't("{generated_key}")'
                    else:
                        replacement_string = original_text  # No replacement needed

                    # Replace the original text with the replacement string
                    return f"{quote_type}{replacement_string}{quote_type}"

                # Apply the specific Japanese string pattern first to catch strings like '福岡県'
                segment = self.specific_japanese_string_pattern.sub(replace_function, segment)

                # Then apply the general pattern for all other cases
                return self.japanese_text_pattern.sub(replace_function, segment)

            # Split the TS code into segments of comments and non-comments
            pos = 0
            for match in self.comment_pattern.finditer(content):
                # Add the non-comment part
                non_comment_part = content[pos:match.start()]
                if non_comment_part:
                    modified_content_segments.append(replace_in_code_segment(non_comment_part))
                # Add the comment part without modification
                modified_content_segments.append(match.group())
                pos = match.end()

            # Add the last non-comment part if it exists
            remaining_code = content[pos:]
            if remaining_code:
                modified_content_segments.append(replace_in_code_segment(remaining_code))

            # Combine all segments back into the modified code
            modified_content = ''.join(modified_content_segments)

            return modified_content, source_json
        except Exception as e:
            raise ResourceFileError(f"WebAppTSFileLocalizer Error in _mark_and_extract_japanese_strings: {str(e)}")

    def _save_ts_file(self, content, ts_file):
        """
        Saves the modified TS file to replace the original.

        :param content: The modified content of the TS file.
        :param ts_file: The path to the TS file being saved.
        """
        try:
            with open(ts_file, 'w', encoding='utf-8') as file:
                file.write(content)
        except Exception as e:
            raise ResourceFileError(f"WebAppTSFileLocalizer Error in _save_ts_file: {str(e)}")






21. web_app_tsx_file_localizer.py:
import re
from localizers.web_localizers.web_app_file_localizer import WebAppFileLocalizer
from managers.error_manager import LocalizationRenderError, ResourceFileError, InvalidUserInputError

class WebAppTSXFileLocalizer(WebAppFileLocalizer):
    """
    The WebAppTSXFileLocalizer handles all TSX file-specific localization procedures.
    It inherits the WebAppFileLocalizer class and manages the localization process.
    """

    def __init__(self, source_code_id, files):
        super().__init__(source_code_id)
        self.files = files

        # Regular expression patterns for identifying Japanese strings while avoiding comments and concatenations
        self.comment_pattern = re.compile(r'//.*?$|/\*.*?\*/', re.DOTALL | re.MULTILINE)

        # Updated pattern to include backtick strings, while excluding concatenated strings and specific cases
        self.japanese_text_pattern = re.compile(r"""
            (?<![\+\w])\s*            # Negative lookbehind to ignore concatenations and object keys
            (["'`])                   # Match opening quote (single, double, or backtick) (capture group 1)
            (                         # Start group for the content to be matched
            (?:[^"'\n]*?)             # Lazily match any characters that are not newlines or quotes
            [\u3000-\u30FF\u4E00-\u9FFF]  # Match Japanese characters
            [^"'\n]*?                 # Lazily match any characters that are not newlines or quotes
            )                         # End group for the content to be matched
            \1                        # Match closing quote (same as opening)
            (?!\s*[\+\w])             # Negative lookahead to ignore concatenations and function calls
            |
            ^\s*(["'`])               # Match isolated opening quote at the beginning (capture group 2)
            (                         # Start group for isolated content to be matched
            (?:[^"'\n]*?)             # Lazily match any characters that are not newlines or quotes
            [\u3000-\u30FF\u4E00-\u9FFF]  # Match Japanese characters
            [^"'\n]*?                 # Lazily match any characters that are not newlines or quotes
            )                         # End group for isolated content to be matched
            \2                        # Match isolated closing quote (same as opening)
            (?![\w\+\)])              # Negative lookahead to avoid concatenations, function calls, or variable names
        """, re.VERBOSE)

        # Pattern to match specific cases like '福岡県' or prompts with Japanese characters
        self.specific_japanese_string_pattern = re.compile(r"""
            (["'`])                    # Match opening quote (capture group 1)
            ([\u3000-\u30FF\u4E00-\u9FFF]+)  # Match only Japanese characters
            \1                        # Match closing quote (same as opening)
        """, re.VERBOSE)


    def localize_files(self):
        """
        Localizes all the TSX files in self.files.
        """
        try:
            for tsx_file in self.files:
                self._process_tsx_file(tsx_file)
            print("Localization completed successfully.")
        except Exception as e:
            raise LocalizationRenderError(f"WebAppTSXFileLocalizer Error in localize_files: {str(e)}")

    def _process_tsx_file(self, tsx_file):
        """
        Processes an individual TSX file for localization.

        :param tsx_file: The path to the TSX file to process.
        """
        try:
            with open(tsx_file, 'r', encoding='utf-8') as file:
                content = file.read()

            modified_content, source_json = self._mark_and_extract_strings(content, tsx_file)

            # Save the extracted strings to a JSON file
            if source_json:
                self.save_resource_files(source_json, tsx_file)

            # Save the modified TSX file using the existing method
            self._save_tsx_file(modified_content, tsx_file)
        except Exception as e:
            raise LocalizationRenderError(f"WebAppTSXFileLocalizer Error in _process_tsx_file: {str(e)}")

    def _mark_and_extract_strings(self, content, tsx_file):
        """
        Marks and extracts all the translatable strings in the TSX file content while preserving comments
        and avoiding concatenated strings.

        :param content: The content of the TSX file.
        :param tsx_file: The path to the TSX file being processed.
        :return: Modified content with placeholders for Japanese texts, and source_json for extracted strings.
        """
        try:
            source_json = {}
            modified_content_segments = []

            # Check if the namespace is enabled in app_settings
            use_namespace = self.app_settings['use_key_namespace']

            # Function to replace Japanese strings in code segments
            def replace_in_code_segment(segment):
                def replace_function(match):
                    # Match group 1 or 2 for quote type, and group 2 or 3 for the text to be replaced
                    quote_type = match.group(1) or match.group(2)
                    original_text = match.group(2) if match.group(1) else match.group(3)

                    # Generate a unique key for the translatable string
                    generated_key = self.generate_key(tsx_file)

                    # Determine the key without namespace for the JSON file
                    key_without_namespace = generated_key.split(':', 1)[-1] if use_namespace else generated_key

                    # Save the extracted string to the JSON file
                    source_json[key_without_namespace] = original_text

                    # Determine the correct replacement string based on quote type
                    if quote_type == "'":
                        # If the original string was in single quotes, use t("{generated_key}") in the replacement
                        replacement_string = f'{{t("{generated_key}")}}'
                    elif quote_type == '"':
                        # If the original string was in double quotes, use t('{generated_key}') in the replacement
                        replacement_string = f"{{t('{generated_key}')}}"
                    elif quote_type == "`":
                        # If the original string was in backtick quotes, use t("{generated_key}") in the replacement
                        replacement_string = f'{{t("{generated_key}")}}'
                    else:
                        replacement_string = original_text  # No replacement needed

                    # Replace the original text with the replacement string
                    return f"{quote_type}{replacement_string}{quote_type}"

                # Apply the specific Japanese string pattern first to catch strings like '福岡県'
                segment = self.specific_japanese_string_pattern.sub(replace_function, segment)

                # Then apply the general pattern for all other cases
                return self.japanese_text_pattern.sub(replace_function, segment)

            # Process div tags first to avoid conflicts with quote_type logic
            modified_content = self._process_tags(content, source_json, tsx_file)

            # Split the TSX code into segments of comments and non-comments
            pos = 0
            for match in self.comment_pattern.finditer(modified_content):
                # Add the non-comment part
                non_comment_part = modified_content[pos:match.start()]
                if non_comment_part:
                    modified_content_segments.append(replace_in_code_segment(non_comment_part))
                # Add the comment part without modification
                modified_content_segments.append(match.group())
                pos = match.end()

            # Add the last non-comment part if it exists
            remaining_code = modified_content[pos:]
            if remaining_code:
                modified_content_segments.append(replace_in_code_segment(remaining_code))

            # Combine all segments back into the modified code
            modified_content = ''.join(modified_content_segments)

            return modified_content, source_json
        except Exception as e:
            raise ResourceFileError(f"WebAppTSXFileLocalizer Error in _mark_and_extract_strings: {str(e)}")

    def _process_tags(self, content, source_json, tsx_file):
        """
        Processes <dt> and <dd> tags in the content, marks and extracts the Japanese text, and adds to source_json.
        
        :param content: The content of the TSX file.
        :param source_json: The dictionary to store extracted strings.
        :param tsx_file: The path to the TSX file being processed.
        :return: Modified content with placeholders for Japanese texts inside <dt> and <dd> tags.
        """
        try:
            # Regular expression patterns for <dt> and <dd> tags individually
            dt_pattern = re.compile(r'<dt[^>]*>.*?</dt>', re.DOTALL)
            dd_pattern = re.compile(r'<dd[^>]*>.*?</dd>', re.DOTALL)
            
            # Function to process individual tag content
            def process_individual_tag(tag_pattern, content):
                modified_content = content
                tags_with_japanese = []

                matches = tag_pattern.findall(content)
                for match in matches:
                    # Check if the tag contains Japanese characters at any level
                    if re.search(r'[\u3000-\u30FF\u4E00-\u9FFF]+', match):
                        tags_with_japanese.append(match)

                # Replace each tag content in the original content
                for tag_content in tags_with_japanese:
                    generated_key = self.generate_key(tsx_file)
                    key_without_namespace = generated_key.split(':', 1)[-1] if self.app_settings['use_key_namespace'] else generated_key
                    source_json[key_without_namespace] = tag_content
                    # Replace the tag content with the localization key placeholder
                    modified_content = modified_content.replace(tag_content, f'{{t("{generated_key}")}}')

                return modified_content

            # Process both <dt> and <dd> tags separately
            content = process_individual_tag(dt_pattern, content)
            content = process_individual_tag(dd_pattern, content)

            return content
        except Exception as e:
            raise ResourceFileError(f"WebAppTSXFileLocalizer Error in _process_tags: {str(e)}")

    def _save_tsx_file(self, content, tsx_file):
        """
        Saves the modified TSX file to replace the original.

        :param content: The modified content of the TSX file.
        :param tsx_file: The path to the TSX file being saved.
        """
        try:
            with open(tsx_file, 'w', encoding='utf-8') as file:
                file.write(content)
        except Exception as e:
            raise ResourceFileError(f"WebAppTSXFileLocalizer Error in _save_tsx_file: {str(e)}")







22. web_app_ejs_file_localizer.py:
import re
from localizers.web_localizers.web_app_file_localizer import WebAppFileLocalizer
from managers.error_manager import LocalizationRenderError, ResourceFileError, InvalidUserInputError

class WebAppEJSFileLocalizer(WebAppFileLocalizer):
    """
    The WebAppEJSFileLocalizer handles all EJS file-specific localization procedures.
    It inherits the WebAppFileLocalizer class and manages the localization process.
    """

    def __init__(self, source_code_id, files):
        super().__init__(source_code_id)
        self.files = files

        # Regular expression patterns for identifying Japanese strings while avoiding comments and concatenations
        self.comment_pattern = re.compile(r'//.*?$|/\*.*?\*/', re.DOTALL | re.MULTILINE)

        # Updated pattern to include backtick strings, while excluding concatenated strings and specific cases
        self.japanese_text_pattern = re.compile(r"""
            (?<![\+\w])\s*            # Negative lookbehind to ignore concatenations and object keys
            (["'`])                   # Match opening quote (single, double, or backtick) (capture group 1)
            (                         # Start group for the content to be matched
            (?:[^"'\n]*?)             # Lazily match any characters that are not newlines or quotes
            [\u3000-\u30FF\u4E00-\u9FFF]  # Match Japanese characters
            [^"'\n]*?                 # Lazily match any characters that are not newlines or quotes
            )                         # End group for the content to be matched
            \1                        # Match closing quote (same as opening)
            (?!\s*[\+\w])             # Negative lookahead to ignore concatenations and function calls
            |
            ^\s*(["'`])               # Match isolated opening quote at the beginning (capture group 2)
            (                         # Start group for isolated content to be matched
            (?:[^"'\n]*?)             # Lazily match any characters that are not newlines or quotes
            [\u3000-\u30FF\u4E00-\u9FFF]  # Match Japanese characters
            [^"'\n]*?                 # Lazily match any characters that are not newlines or quotes
            )                         # End group for isolated content to be matched
            \2                        # Match isolated closing quote (same as opening)
            (?![\w\+\)])              # Negative lookahead to avoid concatenations, function calls, or variable names
        """, re.VERBOSE)

        # Pattern to match specific cases like '福岡県' or prompts with Japanese characters
        self.specific_japanese_string_pattern = re.compile(r"""
            (["'`])                    # Match opening quote (capture group 1)
            ([\u3000-\u30FF\u4E00-\u9FFF]+)  # Match only Japanese characters
            \1                        # Match closing quote (same as opening)
        """, re.VERBOSE)


    def localize_files(self):
        """
        Localizes all the EJS files in self.files.
        """
        try:
            for ejs_file in self.files:
                self._process_ejs_file(ejs_file)
            print("Localization completed successfully.")
        except Exception as e:
            raise LocalizationRenderError(f"WebAppEJSFileLocalizer Error in localize_files: {str(e)}")

    def _process_ejs_file(self, ejs_file):
        """
        Processes an individual EJS file for localization.

        :param ejs_file: The path to the EJS file to process.
        """
        try:
            with open(ejs_file, 'r', encoding='utf-8') as file:
                content = file.read()

            modified_content, source_json = self._mark_and_extract_strings(content, ejs_file)

            # Save the extracted strings to a JSON file
            if source_json:
                self.save_resource_files(source_json, ejs_file)

            # Save the modified EJS file using the existing method
            self._save_ejs_file(modified_content, ejs_file)
        except Exception as e:
            raise LocalizationRenderError(f"WebAppEJSFileLocalizer Error in _process_ejs_file: {str(e)}")

    def _mark_and_extract_strings(self, content, ejs_file):
        """
        Marks and extracts all the translatable strings in the EJS file content while preserving comments
        and avoiding concatenated strings.

        :param content: The content of the EJS file.
        :param ejs_file: The path to the EJS file being processed.
        :return: Modified content with placeholders for Japanese texts, and source_json for extracted strings.
        """
        try:
            source_json = {}
            modified_content_segments = []

            # Check if the namespace is enabled in app_settings
            use_namespace = self.app_settings['use_key_namespace']

            # Function to replace Japanese strings in code segments
            def replace_in_code_segment(segment):
                def replace_function(match):
                    # Match group 1 or 2 for quote type, and group 2 or 3 for the text to be replaced
                    quote_type = match.group(1) or match.group(2)
                    original_text = match.group(2) if match.group(1) else match.group(3)

                    # Generate a unique key for the translatable string
                    generated_key = self.generate_key(ejs_file)

                    # Determine the key without namespace for the JSON file
                    key_without_namespace = generated_key.split(':', 1)[-1] if use_namespace else generated_key

                    # Save the extracted string to the JSON file
                    source_json[key_without_namespace] = original_text

                    # Determine the correct replacement string based on quote type
                    if quote_type == "'":
                        # If the original string was in single quotes, use t("{generated_key}") in the replacement
                        replacement_string = f'${{{{{generated_key}}}}}'
                    elif quote_type == '"':
                        # If the original string was in double quotes, use t('{generated_key}') in the replacement
                        replacement_string = f"${{{{{generated_key}}}}}"
                    elif quote_type == "`":
                        # If the original string was in backtick quotes, use t("{generated_key}") in the replacement
                        replacement_string = f'${{{{{generated_key}}}}}'
                    else:
                        replacement_string = original_text  # No replacement needed

                    # Replace the original text with the replacement string
                    return f"{quote_type}{replacement_string}{quote_type}"

                # Apply the specific Japanese string pattern first to catch strings like '福岡県'
                segment = self.specific_japanese_string_pattern.sub(replace_function, segment)

                # Then apply the general pattern for all other cases
                return self.japanese_text_pattern.sub(replace_function, segment)

            # Process div tags first to avoid conflicts with quote_type logic
            modified_content = self._process_tags(content, source_json, ejs_file)

            # Split the EJS code into segments of comments and non-comments
            pos = 0
            for match in self.comment_pattern.finditer(modified_content):
                # Add the non-comment part
                non_comment_part = modified_content[pos:match.start()]
                if non_comment_part:
                    modified_content_segments.append(replace_in_code_segment(non_comment_part))
                # Add the comment part without modification
                modified_content_segments.append(match.group())
                pos = match.end()

            # Add the last non-comment part if it exists
            remaining_code = modified_content[pos:]
            if remaining_code:
                modified_content_segments.append(replace_in_code_segment(remaining_code))

            # Combine all segments back into the modified code
            modified_content = ''.join(modified_content_segments)

            return modified_content, source_json
        except Exception as e:
            raise ResourceFileError(f"WebAppEJSFileLocalizer Error in _mark_and_extract_strings: {str(e)}")

    def _process_tags(self, content, source_json, ejs_file):
        """
        Processes h1>, <h2>, <h3>, <p>, <li>, <span>, <dt>, and <dd> tags in the content, marks and extracts the Japanese text, and adds to source_json.
        
        :param content: The content of the EJS file.
        :param source_json: The dictionary to store extracted strings.
        :param ejs_file: The path to the EJS file being processed.
        :return: Modified content with placeholders for Japanese texts inside h1>, <h2>, <h3>, <p>, <li>, <span>, <dt>, and <dd> tags.
        """
        try:
            # Regular expression patterns for h1>, <h2>, <h3>, <p>, <li>, <span>, <dt>, and <dd> tags individually
            h1_pattern = re.compile(r'<h1[^>]*>.*?</h1>', re.DOTALL)
            h2_pattern = re.compile(r'<h2[^>]*>.*?</h2>', re.DOTALL)
            h3_pattern = re.compile(r'<h3[^>]*>.*?</h3>', re.DOTALL)
            p_pattern = re.compile(r'<p[^>]*>.*?</p>', re.DOTALL)
            li_pattern = re.compile(r'<li[^>]*>.*?</li>', re.DOTALL)
            span_pattern = re.compile(r'<span[^>]*>.*?</span>', re.DOTALL)
            dt_pattern = re.compile(r'<dt[^>]*>.*?</dt>', re.DOTALL)
            dd_pattern = re.compile(r'<dd[^>]*>.*?</dd>', re.DOTALL)
            
            # Function to process individual tag content
            def process_individual_tag(tag_pattern, content):
                modified_content = content
                tags_with_japanese = []

                matches = tag_pattern.findall(content)
                for match in matches:
                    # Check if the tag contains Japanese characters at any level
                    if re.search(r'[\u3000-\u30FF\u4E00-\u9FFF]+', match):
                        tags_with_japanese.append(match)

                # Replace each tag content in the original content
                for tag_content in tags_with_japanese:
                    generated_key = self.generate_key(ejs_file)
                    key_without_namespace = generated_key.split(':', 1)[-1] if self.app_settings['use_key_namespace'] else generated_key
                    source_json[key_without_namespace] = tag_content
                    # Replace the tag content with the localization key placeholder
                    modified_content = modified_content.replace(tag_content, f'${{{{{generated_key}}}}}')

                return modified_content

            # Process h1>, <h2>, <h3>, <p>, <li>, <span>, <dt>, and <dd> tags individually
            content = process_individual_tag(h1_pattern, content)
            content = process_individual_tag(h2_pattern, content)
            content = process_individual_tag(h3_pattern, content)
            content = process_individual_tag(p_pattern, content)
            content = process_individual_tag(li_pattern, content)
            content = process_individual_tag(span_pattern, content)
            content = process_individual_tag(dt_pattern, content)
            content = process_individual_tag(dd_pattern, content)

            return content
        except Exception as e:
            raise ResourceFileError(f"WebAppEJSFileLocalizer Error in _process_tags: {str(e)}")

    def _save_ejs_file(self, content, ejs_file):
        """
        Saves the modified EJS file to replace the original.

        :param content: The modified content of the EJS file.
        :param ejs_file: The path to the EJS file being saved.
        """
        try:
            with open(ejs_file, 'w', encoding='utf-8') as file:
                file.write(content)
        except Exception as e:
            raise ResourceFileError(f"WebAppEJSFileLocalizer Error in _save_ejs_file: {str(e)}")






23. web_app_vue_file_localizer.py:
import re
from localizers.web_localizers.web_app_file_localizer import WebAppFileLocalizer
from managers.error_manager import LocalizationRenderError, ResourceFileError, InvalidUserInputError

class WebAppVUEFileLocalizer(WebAppFileLocalizer):
    """
    The WebAppVUEFileLocalizer handles all VUE file-specific localization procedures.
    It inherits the WebAppFileLocalizer class and manages the localization process.
    """

    def __init__(self, source_code_id, files):
        super().__init__(source_code_id)
        self.files = files

        # Regular expression patterns for identifying Japanese strings while avoiding comments and concatenations
        self.comment_pattern = re.compile(r'//.*?$|/\*.*?\*/', re.DOTALL | re.MULTILINE)

        # Updated pattern to include backtick strings, while excluding concatenated strings and specific cases
        self.japanese_text_pattern = re.compile(r"""
            (?<![\+\w])\s*            # Negative lookbehind to ignore concatenations and object keys
            (["'`])                   # Match opening quote (single, double, or backtick) (capture group 1)
            (                         # Start group for the content to be matched
            (?:[^"'\n]*?)             # Lazily match any characters that are not newlines or quotes
            [\u3000-\u30FF\u4E00-\u9FFF]  # Match Japanese characters
            [^"'\n]*?                 # Lazily match any characters that are not newlines or quotes
            )                         # End group for the content to be matched
            \1                        # Match closing quote (same as opening)
            (?!\s*[\+\w])             # Negative lookahead to ignore concatenations and function calls
            |
            ^\s*(["'`])               # Match isolated opening quote at the beginning (capture group 2)
            (                         # Start group for isolated content to be matched
            (?:[^"'\n]*?)             # Lazily match any characters that are not newlines or quotes
            [\u3000-\u30FF\u4E00-\u9FFF]  # Match Japanese characters
            [^"'\n]*?                 # Lazily match any characters that are not newlines or quotes
            )                         # End group for isolated content to be matched
            \2                        # Match isolated closing quote (same as opening)
            (?![\w\+\)])              # Negative lookahead to avoid concatenations, function calls, or variable names
        """, re.VERBOSE)

        # Pattern to match specific cases like '福岡県' or prompts with Japanese characters
        self.specific_japanese_string_pattern = re.compile(r"""
            (["'`])                    # Match opening quote (capture group 1)
            ([\u3000-\u30FF\u4E00-\u9FFF]+)  # Match only Japanese characters
            \1                        # Match closing quote (same as opening)
        """, re.VERBOSE)


    def localize_files(self):
        """
        Localizes all the VUE files in self.files.
        """
        try:
            for vue_file in self.files:
                self._process_vue_file(vue_file)
            print("Localization completed successfully.")
        except Exception as e:
            raise LocalizationRenderError(f"WebAppVUEFileLocalizer Error in localize_files: {str(e)}")

    def _process_vue_file(self, vue_file):
        """
        Processes an individual VUE file for localization.

        :param vue_file: The path to the VUE file to process.
        """
        try:
            with open(vue_file, 'r', encoding='utf-8') as file:
                content = file.read()

            modified_content, source_json = self._mark_and_extract_strings(content, vue_file)

            # Save the extracted strings to a JSON file
            if source_json:
                self.save_resource_files(source_json, vue_file)

            # Save the modified VUE file using the existing method
            self._save_vue_file(modified_content, vue_file)
        except Exception as e:
            raise LocalizationRenderError(f"WebAppVUEFileLocalizer Error in _process_vue_file: {str(e)}")

    def _mark_and_extract_strings(self, content, vue_file):
        """
        Marks and extracts all the translatable strings in the VUE file content while preserving comments
        and avoiding concatenated strings.

        :param content: The content of the VUE file.
        :param vue_file: The path to the VUE file being processed.
        :return: Modified content with placeholders for Japanese texts, and source_json for extracted strings.
        """
        try:
            source_json = {}
            modified_content_segments = []

            # Check if the namespace is enabled in app_settings
            use_namespace = self.app_settings['use_key_namespace']

            # Function to replace Japanese strings in code segments
            def replace_in_code_segment(segment):
                def replace_function(match):
                    # Match group 1 or 2 for quote type, and group 2 or 3 for the text to be replaced
                    quote_type = match.group(1) or match.group(2)
                    original_text = match.group(2) if match.group(1) else match.group(3)

                    # Generate a unique key for the translatable string
                    generated_key = self.generate_key(vue_file)

                    # Determine the key without namespace for the JSON file
                    key_without_namespace = generated_key.split(':', 1)[-1] if use_namespace else generated_key

                    # Save the extracted string to the JSON file
                    source_json[key_without_namespace] = original_text

                    # Determine the correct replacement string based on quote type
                    if quote_type == "'":
                        # If the original string was in single quotes, use t("{generated_key}") in the replacement
                        replacement_string = f'{{{{$t("{generated_key}")}}}}'
                    elif quote_type == '"':
                        # If the original string was in double quotes, use t('{generated_key}') in the replacement
                        replacement_string = f"{{{{$t('{generated_key}')}}}}"
                    elif quote_type == "`":
                        # If the original string was in backtick quotes, use t("{generated_key}") in the replacement
                        replacement_string = f'{{{{$t("{generated_key}")}}}}'
                    else:
                        replacement_string = original_text  # No replacement needed

                    # Replace the original text with the replacement string
                    return f"{quote_type}{replacement_string}{quote_type}"

                # Apply the specific Japanese string pattern first to catch strings like '福岡県'
                segment = self.specific_japanese_string_pattern.sub(replace_function, segment)

                # Then apply the general pattern for all other cases
                return self.japanese_text_pattern.sub(replace_function, segment)

            # Process div tags first to avoid conflicts with quote_type logic
            modified_content = self._process_tags(content, source_json, vue_file)

            # Split the VUE code into segments of comments and non-comments
            pos = 0
            for match in self.comment_pattern.finditer(modified_content):
                # Add the non-comment part
                non_comment_part = modified_content[pos:match.start()]
                if non_comment_part:
                    modified_content_segments.append(replace_in_code_segment(non_comment_part))
                # Add the comment part without modification
                modified_content_segments.append(match.group())
                pos = match.end()

            # Add the last non-comment part if it exists
            remaining_code = modified_content[pos:]
            if remaining_code:
                modified_content_segments.append(replace_in_code_segment(remaining_code))

            # Combine all segments back into the modified code
            modified_content = ''.join(modified_content_segments)

            return modified_content, source_json
        except Exception as e:
            raise ResourceFileError(f"WebAppVUEFileLocalizer Error in _mark_and_extract_strings: {str(e)}")

    def _process_tags(self, content, source_json, vue_file):
        """
        Processes h1>, <h2>, <h3>, <p>, <li>, <span>, <dt>, and <dd> tags in the content, marks and extracts the Japanese text, and adds to source_json.
        
        :param content: The content of the VUE file.
        :param source_json: The dictionary to store extracted strings.
        :param vue_file: The path to the VUE file being processed.
        :return: Modified content with placeholders for Japanese texts inside h1>, <h2>, <h3>, <p>, <li>, <span>, <dt>, and <dd> tags.
        """
        try:
            # Regular expression patterns for h1>, <h2>, <h3>, <p>, <li>, <span>, <dt>, and <dd> tags individually
            h1_pattern = re.compile(r'<h1[^>]*>.*?</h1>', re.DOTALL)
            h2_pattern = re.compile(r'<h2[^>]*>.*?</h2>', re.DOTALL)
            h3_pattern = re.compile(r'<h3[^>]*>.*?</h3>', re.DOTALL)
            p_pattern = re.compile(r'<p[^>]*>.*?</p>', re.DOTALL)
            li_pattern = re.compile(r'<li[^>]*>.*?</li>', re.DOTALL)
            span_pattern = re.compile(r'<span[^>]*>.*?</span>', re.DOTALL)
            dt_pattern = re.compile(r'<dt[^>]*>.*?</dt>', re.DOTALL)
            dd_pattern = re.compile(r'<dd[^>]*>.*?</dd>', re.DOTALL)
            
            # Function to process individual tag content
            def process_individual_tag(tag_pattern, content):
                modified_content = content
                tags_with_japanese = []

                matches = tag_pattern.findall(content)
                for match in matches:
                    # Check if the tag contains Japanese characters at any level
                    if re.search(r'[\u3000-\u30FF\u4E00-\u9FFF]+', match):
                        tags_with_japanese.append(match)

                # Replace each tag content in the original content
                for tag_content in tags_with_japanese:
                    generated_key = self.generate_key(vue_file)
                    key_without_namespace = generated_key.split(':', 1)[-1] if self.app_settings['use_key_namespace'] else generated_key
                    source_json[key_without_namespace] = tag_content
                    # Replace the tag content with the localization key placeholder
                    modified_content = modified_content.replace(tag_content, f'{{{{$t("{generated_key}")}}}}')

                return modified_content

            # Process h1>, <h2>, <h3>, <p>, <li>, <span>, <dt>, and <dd> tags individually
            content = process_individual_tag(h1_pattern, content)
            content = process_individual_tag(h2_pattern, content)
            content = process_individual_tag(h3_pattern, content)
            content = process_individual_tag(p_pattern, content)
            content = process_individual_tag(li_pattern, content)
            content = process_individual_tag(span_pattern, content)
            content = process_individual_tag(dt_pattern, content)
            content = process_individual_tag(dd_pattern, content)

            return content
        except Exception as e:
            raise ResourceFileError(f"WebAppVUEFileLocalizer Error in _process_tags: {str(e)}")

    def _save_vue_file(self, content, vue_file):
        """
        Saves the modified VUE file to replace the original.

        :param content: The modified content of the VUE file.
        :param vue_file: The path to the VUE file being saved.
        """
        try:
            with open(vue_file, 'w', encoding='utf-8') as file:
                file.write(content)
        except Exception as e:
            raise ResourceFileError(f"WebAppVUEFileLocalizer Error in _save_vue_file: {str(e)}")







24. web_app_json_file_localizer.py:
# web_app_json_file_localizer.py

import json
from localizers.web_localizers.web_app_file_localizer import WebAppFileLocalizer
from managers.error_manager import LocalizationRenderError, ResourceFileError

class WebAppJSONFileLocalizer(WebAppFileLocalizer):
    """
    The WebAppJSONFileLocalizer handles all JSON file-specific localization procedures.
    It inherits the WebAppFileLocalizer class and manages the localization process.
    """

    def __init__(self, source_code_id, files):
        super().__init__(source_code_id)
        self.files = files

    def localize_files(self):
        """
        Localizes all the JSON files in self.files by duplicating them for each target locale.
        """
        try:
            for json_file in self.files:
                self._process_json_file(json_file)
            print("Localization completed successfully.")
        except Exception as e:
            raise LocalizationRenderError(f"WebAppJSONFileLocalizer Error in localize_files: {str(e)}")

    def _process_json_file(self, json_file):
        """
        Processes an individual JSON file by duplicating it for each target locale.

        :param json_file: The path to the JSON file to process.
        """
        try:
            # Use the duplicate_as_resource_files function to replicate the JSON file
            self.duplicate_as_resource_files(json_file)
        except Exception as e:
            raise ResourceFileError(f"WebAppJSONFileLocalizer Error in _process_json_file: {str(e)}")







25. web_app_csv_file_localizer.py:
# web_app_csv_file_localizer.py

import csv
from localizers.web_localizers.web_app_file_localizer import WebAppFileLocalizer
from managers.error_manager import LocalizationRenderError, ResourceFileError

class WebAppCSVFileLocalizer(WebAppFileLocalizer):
    """
    The WebAppCSVFileLocalizer handles all CSV file-specific localization procedures.
    It inherits the WebAppFileLocalizer class and manages the localization process.
    """

    def __init__(self, source_code_id, files):
        super().__init__(source_code_id)
        self.files = files

    def localize_files(self):
        """
        Localizes all the CSV files in self.files by duplicating them for each target locale.
        """
        try:
            for csv_file in self.files:
                self._process_csv_file(csv_file)
            print("Localization completed successfully.")
        except Exception as e:
            raise LocalizationRenderError(f"WebAppCSVFileLocalizer Error in localize_files: {str(e)}")

    def _process_csv_file(self, csv_file):
        """
        Processes an individual CSV file by duplicating it for each target locale.

        :param csv_file: The path to the CSV file to process.
        """
        try:
            # Use the duplicate_as_resource_files function to replicate the CSV file
            self.duplicate_as_resource_files(csv_file)
        except Exception as e:
            raise ResourceFileError(f"WebAppCSVFileLocalizer Error in _process_csv_file: {str(e)}")
